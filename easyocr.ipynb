{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "841fd6d4",
   "metadata": {},
   "source": [
    "# EasyOCR custom model\n",
    "\n",
    "## TextRecognitionDataGenerator\n",
    "\n",
    "Dataset does not have to be generated within XGEE\\\n",
    "Instead, generating a dataset using the [TextRecognitionDataGenerator](https://github.com/Belval/TextRecognitionDataGenerator) with custom parameters to mirror XGEE's font style\\\n",
    "This dataset can be used to train own model by following the [deep-text-recognition-benchmark Repo](https://github.com/clovaai/deep-text-recognition-benchmark)\\\n",
    "Has to be fully convolutional to work with large variety of Text sizes and potentially orientations\\\n",
    "2 additional files describing recognition network architecture and model configuration needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf3f348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fallback_with_easyocr(self):\n",
    "    \"\"\"Fallback OCR engine: EasyOCR.\"\"\"\n",
    "    \n",
    "    import easyocr\n",
    "\n",
    "    logging.info('\\n\\nNow detecting text in the diagram.')\n",
    "    target_img = self.image_wrapper.bgr_image\n",
    "    target_img = TextDetector.fallback_pad_image_to_square(target_img)\n",
    "    easyocr_img = target_img.copy()\n",
    "    scale_factor = 2\n",
    "    easyocr_img = cv2.resize(easyocr_img, None, fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_LINEAR)\n",
    "    easyocr_img = cv2.blur(easyocr_img, (5, 5))\n",
    "\n",
    "    logging.getLogger('easyocr').setLevel(logging.CRITICAL)\n",
    "    reader = TextDetector.fallback_create_ocr_reader(['en'])\n",
    "\n",
    "    result = TextDetector.fallback_extract_text_from_image(reader, easyocr_img)\n",
    "    logging.info(f'Number of words found in the original image: {len(result)}')\n",
    "    short_words_count = len([detection for detection in result if len(detection[1]) < 5])\n",
    "    logging.info(f'Number of words smaller than 5 letters: {short_words_count}')\n",
    "\n",
    "    # Rotate the image by 90 degrees counterclockwise and search for text\n",
    "    rotated_img = TextDetector.fallback_rotate_image(easyocr_img, 90)\n",
    "\n",
    "    rotated_result = TextDetector.fallback_extract_text_from_image(reader, rotated_img)\n",
    "    logging.info(f'Number of words found in the rotated image: {len(rotated_result)}')\n",
    "    short_words_count = len([detection for detection in rotated_result if len(detection[1]) < 5])\n",
    "    logging.info(f'Number of words smaller than 5 letters: {short_words_count}')\n",
    "\n",
    "    # Adjust the coordinates of the rotated text and combine results\n",
    "    result = TextDetector.fallback_adjust_and_combine_results(result, rotated_result, easyocr_img.shape, 90)\n",
    "    # remove padding from the bounding boxes\n",
    "    result = TextDetector.fallback_adjust_bounding_boxes(result)\n",
    "    \n",
    "    # Revert the coordinates of the found text to the coordinates in the not-upscaled image\n",
    "    for detection in result:\n",
    "        for point in detection[0]:\n",
    "            point[0] = int(point[0] / scale_factor)\n",
    "            point[1] = int(point[1] / scale_factor)\n",
    "\n",
    "    # Filter out short texts from the results\n",
    "    result = TextDetector.fallback_filter_short_texts(result)\n",
    "\n",
    "    # # Filter out forbidden characters from the results\n",
    "    # result = TextDetector.fallback_filter_forbidden_chars(result, forbidden_chars)\n",
    "    # logging.info(f'Number of words found after filtering: {len(result)}')\n",
    "\n",
    "    result = TextDetector.fallback_adjust_text_box_positions(result, self.image_wrapper.bgr_image.shape)\n",
    "\n",
    "    # Convert text box tuples to instances of TextBox\n",
    "    text_boxes_typed = [TextBox(x=box[0][0][0], y=box[0][0][1], width=box[0][2][0] - box[0][0][0], height=box[0][2][1] - box[0][0][1], text=box[1], confidence=box[2]) for box in result]\n",
    "\n",
    "    # Store the merged boxes\n",
    "    self.data_storage.store_geometric_shape_collection(TextBoxCollection('text', text_boxes_typed))\n",
    "\n",
    "    # Log debug images showing detected text\n",
    "    image_with_text_boxes = self.image_wrapper.bgr_image.copy()\n",
    "    for box in text_boxes_typed:\n",
    "        cv2.rectangle(image_with_text_boxes, (box.x, box.y), (box.x + box.width, box.y + box.height), (0, 255, 0), 2)\n",
    "        cv2.putText(image_with_text_boxes, box.text, (box.x, box.y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    ImageLogger.log_image(image_with_text_boxes, 'DEBUG', 'image_with_text_boxes.png')        \n",
    "\n",
    "def fallback_pad_image_to_square(image):\n",
    "    \"\"\"Pad the image to make it square.\"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    if h == w:\n",
    "        return image\n",
    "    size = max(h, w)\n",
    "    padded_image = cv2.copyMakeBorder(image, \n",
    "                                        top=(size - h) // 2,\n",
    "                                        bottom=(size - h + 1) // 2,\n",
    "                                        left=(size - w) // 2,\n",
    "                                        right=(size - w + 1) // 2,\n",
    "                                        borderType=cv2.BORDER_CONSTANT,\n",
    "                                        value=[255, 255, 255])\n",
    "    return padded_image\n",
    "\n",
    "def fallback_create_ocr_reader(languages):\n",
    "    \"\"\"Create an OCR reader object.\"\"\"\n",
    "    return easyocr.Reader(languages, gpu=False) # set gpu=False if you want to use CPU\n",
    "\n",
    "def fallback_extract_text_from_image(reader, image):\n",
    "    \"\"\"Extract text from an image using the OCR reader.\"\"\"\n",
    "    return reader.readtext(image, detail=1)\n",
    "\n",
    "def fallback_adjust_bounding_boxes(results, padding_top=9, padding_bottom=6, padding_left=8, padding_right=8):\n",
    "    \"\"\"Adjust bounding boxes to remove padding.\"\"\"\n",
    "    for detection in results:\n",
    "        for point in detection[0]:\n",
    "            if point[0] < detection[0][1][0]:  # Left side\n",
    "                point[0] += padding_left\n",
    "            else:  # Right side\n",
    "                point[0] -= padding_right\n",
    "            if point[1] < detection[0][3][1]:  # Top side\n",
    "                point[1] += padding_top\n",
    "            else:  # Bottom side\n",
    "                point[1] -= padding_bottom\n",
    "    return results\n",
    "\n",
    "def fallback_rotate_image(image, angle):\n",
    "    \"\"\"Rotate the image by the given angle.\"\"\"\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w / 2, h / 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h))\n",
    "    return rotated\n",
    "\n",
    "def fallback_rotate_point(point, angle, center):\n",
    "    \"\"\"Rotate a point around a center by a given angle.\"\"\"\n",
    "    angle_rad = -angle * (3.14159265 / 180.0)\n",
    "    ox, oy = center\n",
    "    px, py = point\n",
    "\n",
    "    qx = ox + (px - ox) * cos(angle_rad) - (py - oy) * sin(angle_rad)\n",
    "    qy = oy + (px - ox) * sin(angle_rad) + (py - oy) * cos(angle_rad)\n",
    "    return [int(qx), int(qy)]\n",
    "\n",
    "def fallback_adjust_and_combine_results(original_result, rotated_result, image_shape, angle):\n",
    "    \"\"\"Adjust the coordinates of the rotated text and combine results.\"\"\"\n",
    "    (h, w) = image_shape[:2]\n",
    "    center = (w / 2, h / 2)\n",
    "    for detection in rotated_result:\n",
    "        rotated_bbox = [TextDetector.fallback_rotate_point(point, -angle, center) for point in detection[0]]\n",
    "        original_result.append([rotated_bbox, detection[1], detection[2]])\n",
    "    return original_result\n",
    "\n",
    "def fallback_filter_short_texts(detections, min_length=5): # min_length>=3, otherwise false positives\n",
    "    \"\"\"Filter out text detections that are shorter than the specified minimum length.\"\"\"\n",
    "    return [detection for detection in detections if len(detection[1]) >= min_length]\n",
    "\n",
    "def fallback_filter_forbidden_chars(detections, forbidden_chars):\n",
    "    \"\"\"Filter out text detections that are only one letter and are in the forbidden characters list.\"\"\"\n",
    "    return [detection for detection in detections if not (len(detection[1]) == 1 and detection[1] in forbidden_chars)]\n",
    "\n",
    "def fallback_adjust_text_box_positions(result, image_shape):\n",
    "    \"\"\"Adjust the position of the text boxes to account for the padding.\"\"\"\n",
    "    h, w = image_shape[:2]\n",
    "    size = max(h, w)\n",
    "    pad_top = (size - h) // 2\n",
    "    pad_left = (size - w) // 2\n",
    "    for detection in result:\n",
    "        for point in detection[0]:\n",
    "            point[0] -= pad_left\n",
    "            point[1] -= pad_top\n",
    "    return result\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
